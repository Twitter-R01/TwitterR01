{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying tweet relevance to vaping with supervised machine learning algorithms\n",
    "\n",
    "Authors: Patrick O'Halloran and Sanya Taneja\n",
    "\n",
    "Home repository: https://github.com/CRMTH/AnnotationProjects\n",
    "\n",
    "Summary: We evaluate several classification algorithms with 2000 annotated tweets in Dataset 1 (D1). The target of this analysis is relevance as coded by annotators (note: would be good to report inter-rater reliability metrics here). For classification, we evaluate the Bernoulli Naive Bayes, Random Forest, Logistic Regression, and Linear SVM algorithms, while comparing count vectorization with the TFIDF statistic for feature engineering. We find that the best combination of algorithms and feature engineering with respect to the accuracy evaluation metric is Logistic Regression using count vectorization to construct features. We anticipate this result will not generalize as the dataset grows.\n",
    "\n",
    "First, we import all python libraries and read in D1, which we preprocess using nlp_preprocess.py (written by Sanya) prior to analysis. Below, we display a sample of both relevant and non-relevant tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>text</th>\n",
       "      <th>quote</th>\n",
       "      <th>relevant</th>\n",
       "      <th>com_vape</th>\n",
       "      <th>news_vape</th>\n",
       "      <th>pro_vape</th>\n",
       "      <th>anti_vape</th>\n",
       "      <th>metadata_text</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>unicode_count</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>keyword_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'1037612658755821568</td>\n",
       "      <td>20% discount ON UBLO  CBD E-Liquids ENTER UBL...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discount ublo cbd e liquid enter ublo checkout...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>discount ublo cbd e liquid enter ublo checkout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'1032695372110413824</td>\n",
       "      <td>New Vaping SMOK Rolo Badge Starter Kit 250mAh...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>new vape smok rolo badg starter kit mah</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>new vape smok rolo badg starter kit mah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'1032148741359370240</td>\n",
       "      <td>knew she was real when it wasn't a Juul but a...</td>\n",
       "      <td>if you can smoke a jack &amp; beat my ass like th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>knew real neg_a neg_juul neg_but neg_a jack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>knew real neg_a neg_juul neg_but neg_a jack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'1031947667851472896</td>\n",
       "      <td>Take a minute today to check out some of the ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>take minut today check new e juic help peopl a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>take minut today check new e juic help peopl a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'1030995802305396736</td>\n",
       "      <td>New Vaping Vaporesso Revenger X 220W Kit with...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>new vape vaporesso reveng x w kit nrg tank ml ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>new vape vaporesso reveng x w kit nrg tank ml ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'1037013414550228992</td>\n",
       "      <td>Parang ka usok ng vape napapasaya mo ako pero...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>parang ka usok ng vape napapasaya mo ako pero ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>parang ka usok ng vape napapasaya mo ako pero ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'1033243474760323072</td>\n",
       "      <td>@hazim_wafiy</td>\n",
       "      <td>Sebab apa aku prefer # NanoSTIX dari rokok da...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'1034414473413517312</td>\n",
       "      <td>Nasty punya company semakin mantap dah. Try l...</td>\n",
       "      <td>Job vacancy. _newline_ Office yang suasananya...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nasti punya compani semakin mantap dah tri lah...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>nasti punya compani semakin mantap dah tri lah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'1032458291983659008</td>\n",
       "      <td>2nd\\u3044\\u3088\\u3044\\u3088\\u660e\\u65e5\\u767a...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nd vsc vscmod vscmodjapan kiyomasa nd vape vap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>nd vsc vscmod vscmodjapan kiyomasa nd vape vap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'1036301216592982016</td>\n",
       "      <td>Ada lagi eh lelaki ceni sekarang?</td>\n",
       "      <td>Jangan tinggalkan lelaki yang: _newline_ 1.Ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ada lagi eh lelaki ceni sekarang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>ada lagi eh lelaki ceni sekarang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweetID                                               text  \\\n",
       "0   '1037612658755821568   20% discount ON UBLO  CBD E-Liquids ENTER UBL...   \n",
       "1   '1032695372110413824   New Vaping SMOK Rolo Badge Starter Kit 250mAh...   \n",
       "2   '1032148741359370240   knew she was real when it wasn't a Juul but a...   \n",
       "3   '1031947667851472896   Take a minute today to check out some of the ...   \n",
       "4   '1030995802305396736   New Vaping Vaporesso Revenger X 220W Kit with...   \n",
       "5   '1037013414550228992   Parang ka usok ng vape napapasaya mo ako pero...   \n",
       "6   '1033243474760323072                                      @hazim_wafiy    \n",
       "8   '1034414473413517312   Nasty punya company semakin mantap dah. Try l...   \n",
       "26  '1032458291983659008   2nd\\u3044\\u3088\\u3044\\u3088\\u660e\\u65e5\\u767a...   \n",
       "27  '1036301216592982016                 Ada lagi eh lelaki ceni sekarang?    \n",
       "\n",
       "                                                quote  relevant  com_vape  \\\n",
       "0                                                             1         1   \n",
       "1                                                             1         1   \n",
       "2    if you can smoke a jack & beat my ass like th...         1         0   \n",
       "3                                                             1         1   \n",
       "4                                                             1         1   \n",
       "5                                                             0         0   \n",
       "6    Sebab apa aku prefer # NanoSTIX dari rokok da...         0         0   \n",
       "8    Job vacancy. _newline_ Office yang suasananya...         0         0   \n",
       "26                                                            0         0   \n",
       "27   Jangan tinggalkan lelaki yang: _newline_ 1.Ta...         0         0   \n",
       "\n",
       "    news_vape  pro_vape  anti_vape  \\\n",
       "0           0         0          0   \n",
       "1           0         0          0   \n",
       "2           0         0          1   \n",
       "3           0         0          0   \n",
       "4           0         0          0   \n",
       "5           0         0          0   \n",
       "6           0         0          0   \n",
       "8           0         0          0   \n",
       "26          0         0          0   \n",
       "27          0         0          0   \n",
       "\n",
       "                                        metadata_text  mention_count  \\\n",
       "0   discount ublo cbd e liquid enter ublo checkout...              0   \n",
       "1             new vape smok rolo badg starter kit mah              0   \n",
       "2         knew real neg_a neg_juul neg_but neg_a jack              0   \n",
       "3   take minut today check new e juic help peopl a...              0   \n",
       "4    new vape vaporesso reveng x w kit nrg tank ml ml              0   \n",
       "5   parang ka usok ng vape napapasaya mo ako pero ...              0   \n",
       "6                                                 NaN              0   \n",
       "8   nasti punya compani semakin mantap dah tri lah...              0   \n",
       "26  nd vsc vscmod vscmodjapan kiyomasa nd vape vap...              0   \n",
       "27                   ada lagi eh lelaki ceni sekarang              0   \n",
       "\n",
       "    url_count  unicode_count  emoji_count  hashtag_count  keyword_count  \\\n",
       "0           0              0            0              0              1   \n",
       "1           0              0            0              0              1   \n",
       "2           0              0            0              0              0   \n",
       "3           0              0            0              0              1   \n",
       "4           0              0            0              0              1   \n",
       "5           0              0            0              0              1   \n",
       "6           0              0            0              0              0   \n",
       "8           0              0            0              0              0   \n",
       "26          0              0            0              0              3   \n",
       "27          0              0            0              0              0   \n",
       "\n",
       "   hashtags                                         clean_text  \n",
       "0        []  discount ublo cbd e liquid enter ublo checkout...  \n",
       "1        []            new vape smok rolo badg starter kit mah  \n",
       "2        []        knew real neg_a neg_juul neg_but neg_a jack  \n",
       "3        []  take minut today check new e juic help peopl a...  \n",
       "4        []   new vape vaporesso reveng x w kit nrg tank ml ml  \n",
       "5        []  parang ka usok ng vape napapasaya mo ako pero ...  \n",
       "6        []                                                NaN  \n",
       "8        []  nasti punya compani semakin mantap dah tri lah...  \n",
       "26       []  nd vsc vscmod vscmodjapan kiyomasa nd vape vap...  \n",
       "27       []                   ada lagi eh lelaki ceni sekarang  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import python libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "\n",
    "# read in data and display first 5 rows for relevant and non-relevant tweets\n",
    "d1 = pd.read_table('./data/processed_D1.tsv')\n",
    "d1.groupby('relevant').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we describe the completeness of D1 and check how much data is lost by dropping rows with any null values. In so doing, we end up with 1965 tweets available for evaluating various classifier algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 17 columns):\n",
      "tweetID          2000 non-null object\n",
      "text             2000 non-null object\n",
      "quote            2000 non-null object\n",
      "relevant         2000 non-null int64\n",
      "com_vape         2000 non-null int64\n",
      "news_vape        2000 non-null int64\n",
      "pro_vape         2000 non-null int64\n",
      "anti_vape        2000 non-null int64\n",
      "metadata_text    1965 non-null object\n",
      "mention_count    2000 non-null int64\n",
      "url_count        2000 non-null int64\n",
      "unicode_count    2000 non-null int64\n",
      "emoji_count      2000 non-null int64\n",
      "hashtag_count    2000 non-null int64\n",
      "keyword_count    2000 non-null int64\n",
      "hashtags         2000 non-null object\n",
      "clean_text       1965 non-null object\n",
      "dtypes: int64(11), object(6)\n",
      "memory usage: 265.7+ KB\n"
     ]
    }
   ],
   "source": [
    "d1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1965 entries, 0 to 1999\n",
      "Data columns (total 17 columns):\n",
      "tweetID          1965 non-null object\n",
      "text             1965 non-null object\n",
      "quote            1965 non-null object\n",
      "relevant         1965 non-null int64\n",
      "com_vape         1965 non-null int64\n",
      "news_vape        1965 non-null int64\n",
      "pro_vape         1965 non-null int64\n",
      "anti_vape        1965 non-null int64\n",
      "metadata_text    1965 non-null object\n",
      "mention_count    1965 non-null int64\n",
      "url_count        1965 non-null int64\n",
      "unicode_count    1965 non-null int64\n",
      "emoji_count      1965 non-null int64\n",
      "hashtag_count    1965 non-null int64\n",
      "keyword_count    1965 non-null int64\n",
      "hashtags         1965 non-null object\n",
      "clean_text       1965 non-null object\n",
      "dtypes: int64(11), object(6)\n",
      "memory usage: 276.3+ KB\n"
     ]
    }
   ],
   "source": [
    "d1.dropna().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.dropna(inplace=True)\n",
    "d1.reset_index(drop=True,inplace=True)\n",
    "x = d1.clean_text\n",
    "y = d1.relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 5-fold cross validation to assess the performance of logistic regression with L2 regularization, linear SVM with L2 regularization, Bernoulli naive Bayes, and random forest algorithms. Using scikit-learn, we construct a pipeline to search for the best parameters over a large parameter space  (# of count vectorized features, choice of uni/bi/trigrams, and classifier hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21330 candidates, totalling 106650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2936 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4344 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6008 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7928 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 10104 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12536 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 15224 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18168 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 21368 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 24824 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 27097 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 28089 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 29145 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 30265 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 31449 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 32697 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 34009 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done 35385 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 36825 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done 38329 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 39897 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 41529 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 43225 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 44985 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=-1)]: Done 46809 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=-1)]: Done 48697 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 50649 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done 52665 tasks      | elapsed: 35.3min\n",
      "[Parallel(n_jobs=-1)]: Done 54745 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 56889 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=-1)]: Done 59097 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=-1)]: Done 61369 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done 63705 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=-1)]: Done 66105 tasks      | elapsed: 50.5min\n",
      "[Parallel(n_jobs=-1)]: Done 68569 tasks      | elapsed: 53.1min\n",
      "[Parallel(n_jobs=-1)]: Done 71097 tasks      | elapsed: 55.8min\n",
      "[Parallel(n_jobs=-1)]: Done 73689 tasks      | elapsed: 58.4min\n",
      "[Parallel(n_jobs=-1)]: Done 76345 tasks      | elapsed: 61.3min\n",
      "[Parallel(n_jobs=-1)]: Done 79065 tasks      | elapsed: 64.3min\n",
      "[Parallel(n_jobs=-1)]: Done 81849 tasks      | elapsed: 67.3min\n",
      "[Parallel(n_jobs=-1)]: Done 84697 tasks      | elapsed: 70.5min\n",
      "[Parallel(n_jobs=-1)]: Done 87609 tasks      | elapsed: 73.9min\n",
      "[Parallel(n_jobs=-1)]: Done 90585 tasks      | elapsed: 77.0min\n",
      "[Parallel(n_jobs=-1)]: Done 93625 tasks      | elapsed: 80.5min\n",
      "[Parallel(n_jobs=-1)]: Done 96729 tasks      | elapsed: 83.9min\n",
      "[Parallel(n_jobs=-1)]: Done 99897 tasks      | elapsed: 87.2min\n",
      "[Parallel(n_jobs=-1)]: Done 103129 tasks      | elapsed: 91.4min\n",
      "[Parallel(n_jobs=-1)]: Done 106425 tasks      | elapsed: 95.3min\n",
      "[Parallel(n_jobs=-1)]: Done 106650 out of 106650 | elapsed: 95.6min finished\n",
      "/home/pmo14/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...enalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'clf__estimator': [LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)], 've...'], 'clf__estimator__max_depth': [4, 5, 6, 7, 8], 'clf__estimator__criterion': ['gini', 'entropy']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class ClassifierPipeline(BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator = LogisticRegression(),):\n",
    "        \"\"\"\n",
    "        A custom BaseEstimator that can switch between classifiers in the pipe.\n",
    "        Defaults to Logistic Regression.\n",
    "        \n",
    "        :param estimator: sklearn object; switches between any sklearn estimator\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)\n",
    "    \n",
    "cvec = CountVectorizer()\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec), ('clf', ClassifierPipeline())])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'clf__estimator': [LogisticRegression()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'clf__estimator__penalty': ['l2'],\n",
    "        'clf__estimator__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [LinearSVC()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'clf__estimator__penalty': ['l2'],\n",
    "        'clf__estimator__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [BernoulliNB()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'clf__estimator__alpha': np.logspace(-4, 4, 5),\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [RandomForestClassifier()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'clf__estimator__n_estimators': [200, 500],\n",
    "        'clf__estimator__max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'clf__estimator__max_depth': [4,5,6,7,8],\n",
    "        'clf__estimator__criterion': ['gini', 'entropy'],\n",
    "    },\n",
    "]\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, return_train_score=False, verbose=3)\n",
    "search.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that logistic regression with L2 regularization performs the best, with a CV accuracy of 0.884. The logistic regression model performed best with a regularization parameter, C, of 10. It also used count vectorization to construct features from the preprocessed tweet text with 3700 trigram features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.884):\n",
      "{'clf__estimator': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'clf__estimator__C': 10, 'clf__estimator__penalty': 'l2', 'vectorizer__max_features': 3700, 'vectorizer__ngram_range': (1, 3), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "### add dictionary of scores; refit AUC for best CV set of params\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add the NLP preprocess pipeline as a custom transformer to be used in the pipeline above as the step prior to vectorization and classification. Using the transformer in the pipeline will let us know the combination of text preprocessing options that gives the best results. \n",
    "\n",
    "Transformer calls the nlp_preprocess function used above for cleaning the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load nlp_preprocess.py\n",
    "\"\"\"\n",
    "Version: 03-13-2019\n",
    "Author: sanyabt\n",
    "\"\"\"\n",
    "import re, string, sys\n",
    "from nltk import tokenize\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "'''\n",
    "Replace emojis with text translations given in emoji list (emojis: dictionary of translated emojis).\n",
    "'''\n",
    "def emojify(text, emojis):\n",
    "\ttext = str(text.encode('unicode-escape'))[2:-1]\n",
    "\tif '\\\\u' in text.lower():\n",
    "\t\ttext = text.replace('\\\\\\\\U' , '\\\\\\\\u')\n",
    "\t\ttext = text.replace('\\\\\\\\u' , ' \\\\\\\\u')\n",
    "\t\twords = text.split(' ')\n",
    "\t\tfor word in words:\n",
    "\t\t\tif '\\\\u' in word:\n",
    "\t\t\t\tif word in emojis.keys():\n",
    "\t\t\t\t\twords[words.index(word)] = emojis[word]\n",
    "\t\t\t\telif word[0:11] in emojis:\n",
    "\t\t\t\t\tword_1 = word[11:len(word)]\n",
    "\t\t\t\t\twords[words.index(word)] = emojis[word[0:11]] + ' ' + word_1\n",
    "\t\t\t\telif word[0:7] in emojis:\n",
    "\t\t\t\t\tword_1 = word[7:len(word)]\n",
    "\t\t\t\t\twords[words.index(word)] = emojis[word[0:7]] + ' ' + word_1\n",
    "\t\treturn ' '.join(words)\n",
    "\treturn text\n",
    "\n",
    "'''\n",
    "Remove translated emojis from text from text.\n",
    "'''\n",
    "def emoji_remove(text):\n",
    "\twords = tokenize.word_tokenize(text)\n",
    "\tfor word in words:\n",
    "\t\tif 'emoj_' in word:\n",
    "\t\t\twords[words.index(word)] = ''\n",
    "\treturn ' '.join(words)\n",
    "\n",
    "'''\n",
    "Remove twitter metadata information (_url_, _mention_, _hashtag_ etc) from text (excluding emojis).\n",
    "'''\n",
    "def metadata_remove(text):\n",
    "\twords = tokenize.word_tokenize(text)\n",
    "\tfor word in words:\n",
    "\t\tif '_' in word and 'neg_' not in word and 'emoj_' not in word:\n",
    "\t\t\twords[words.index(word)] = ''\n",
    "\treturn ' '.join(words)\n",
    "\n",
    "'''\n",
    "Replace twitter url's, hashtags, unrecognized unicodes and mentions.\n",
    "'''\n",
    "def metadata_clean(text, url_pat, unicode_pat, mention_pat):\n",
    "\t#Handle URL's\n",
    "\ttext = url_pat.sub('_url_', text)\n",
    "\n",
    "\t#Unidentified unicodes\n",
    "\ttext = unicode_pat.sub('_unicode_', text)\n",
    "\t\n",
    "\t#Handle @mentions and hashtags\n",
    "\ttext = mention_pat.sub('_mention_', text)\n",
    "\ttext = text.replace('#', '_hashtag_')\n",
    "\t\n",
    "\t#remove extra backslack due to post-parse emojify, but dont want to remove the \\ in other unicodes\n",
    "\ttext = text.replace('\\\\', '')\n",
    "\treturn text\n",
    "\n",
    "'''\n",
    "Expand the negation words in text using negation dictionary (defined below).\n",
    "'''\n",
    "def negation_expand(text, neg_pattern, negations_dic):\n",
    "\t\n",
    "\t#Expand negation contractions mentioned in negations dictionary\n",
    "\ttext = neg_pattern.sub(lambda x: negations_dic[x.group()], text)\n",
    "\treturn text\n",
    "\n",
    "'''\n",
    "Remove punctuation from text. Returns tokenized text either with or without punctuation.\n",
    "'''\n",
    "def punctuation_remove(text):\n",
    "\n",
    "\ttzer = tokenize.RegexpTokenizer(r'[A-Za-z0-9_]+')\n",
    "\ttokenized = tzer.tokenize(text)\n",
    "\treturn ' '.join(tokenized)\n",
    "\n",
    "'''\n",
    "Remove digits from text.\n",
    "'''\n",
    "def digits_remove(text):\n",
    "\tresult = ''.join(i for i in text if not i.isdigit())\n",
    "\treturn result\n",
    "\n",
    "def check_negation(token):\n",
    "\tflag = False\n",
    "\tif token in string.punctuation:\n",
    "\t\tflag = True\n",
    "\t\treturn False, flag\n",
    "\tif '_' in token:\n",
    "\t\treturn False, flag\n",
    "\telse:\n",
    "\t\treturn True, flag\n",
    "\n",
    "'''\n",
    "Negation marking of text for all negation words defined below. \n",
    "1. Find all negation words in the text\n",
    "2. Add NEG_ to tokens following the negation word till the next punctuation (end of sentence) - if punctuation present in next 4 tokens\n",
    "3. Else add NEG_ to next 4 tokens (non-punctuation)\n",
    "'''\n",
    "def negation_marking(text, neg_mark_pattern):\n",
    "\ttokens = tokenize.word_tokenize(text)\n",
    "\tneg_matched = neg_mark_pattern.findall(' '.join(tokens))\n",
    "\t\n",
    "\tfor item in neg_matched:\n",
    "\t\tif item in tokens:\n",
    "\t\t\tloc = tokens.index(item)\n",
    "\t\t\n",
    "\t\t\tif (len(tokens) - loc) <= 4:\n",
    "\t\t\t\tfor tok in tokens[loc+1:]:\n",
    "\t\t\t\t\tans, flag = check_negation(tok)\n",
    "\t\t\t\t\tif ans is True:\n",
    "\t\t\t\t\t\ttokens[tokens.index(tok)] = 'NEG_'+tok\n",
    "\t\t\t\t\tif flag is True:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor tok in tokens[loc+1:loc+5]:\n",
    "\t\t\t\t\tans, flag = check_negation(tok)\n",
    "\t\t\t\t\tif ans is True:\n",
    "\t\t\t\t\t\ttokens[tokens.index(tok)] = 'NEG_'+tok\n",
    "\t\t\t\t\tif flag is True:\n",
    "\t\t\t\t\t\tbreak\n",
    "\treturn ' '.join(tokens)\n",
    "\n",
    "'''\n",
    "Fix lengthening in text where consecutive similar characters occurring more than 2 times are reduced to 2.\n",
    "'''\n",
    "def normalize_text(text, pattern):\n",
    "\treturn pattern.sub(r\"\\1\\1\", text)\n",
    "\t\n",
    "'''\n",
    "Remove stopwords from text using NLTK English stopwords list.\n",
    "'''\n",
    "def stopwords_remove(text):\n",
    "\twords = tokenize.word_tokenize(text)\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\twords = [word for word in words if word.lower() not in stop_words]\n",
    "\treturn ' '.join(words)\n",
    "\n",
    "'''\n",
    "Porter stemming algorithm applied to the text. Note: converts text to lowercase and also stem stopwords (such as 'was' to 'wa'). Do with caution.\n",
    "'''\n",
    "def stemming_apply(text, stemmer):\n",
    "\ttokens = tokenize.word_tokenize(text)\n",
    "\tstems = []\n",
    "\tfor t in tokens:\n",
    "\t\tstems.append(stemmer.stem(t))\n",
    "\treturn ' '.join(stems)\n",
    "\n",
    "'''\n",
    "Based on text options specified, run the pipeline and process tweets text.\n",
    "'''\n",
    "def preprocess(tweets, text_options):\n",
    "\n",
    "\t#Translate emojis for all tweets (this is the default in parsing)\n",
    "\temojis = {}\n",
    "\twith open('data/emojilist5.csv', 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tunic=line.split(',')[0].lower()\n",
    "\t\t\ttrans=line.split(',')[1]\n",
    "\t\t\temojis[unic]=trans\n",
    "\ttweets = tweets.apply(emojify, args=(emojis,))\n",
    "\t\n",
    "\t#Metadata information clean for all tweets\n",
    "\tpat1 = r'https?://[A-Za-z0-9./]+'\n",
    "\tpat2 = r'www\\\\.[^ ]+'\n",
    "\tcombined_pat = r'|'.join((pat1, pat2))\n",
    "\turl_pat = re.compile(combined_pat)\n",
    "\n",
    "\tpat3 = r'\\\\u[^ ]+'\n",
    "\tunicode_pat = re.compile(pat3)\n",
    "\n",
    "\tpat4 = r'@[A-Za-z0-9_]+'\n",
    "\tmention_pat = re.compile(pat4)\n",
    "\ttweets = tweets.apply(metadata_clean, args=(url_pat, unicode_pat, mention_pat))\n",
    "\n",
    "\t#Expand negations\n",
    "\tif text_options['negation_expand'] is True:\n",
    "\t\tnegations_dic = {\"isn\\'t\" : \"is not\",\n",
    "\t\t\t\t\"aren\\'t\" : \"are not\",\n",
    "\t\t\t\t\"wasn\\'t\" : \"was not\",\n",
    "\t\t\t\t\"weren\\'t\" : \"were not\",\n",
    "\t\t\t\t\"haven\\'t\" : \"have not\",\n",
    "\t\t\t\t\"hasn\\'t\" : \"has not\",\n",
    "\t\t\t\t\"hadn\\'t\" : \"had not\",\n",
    "\t\t\t\t\"won\\'t\" : \"will not\",\n",
    "\t\t\t\t\"wouldn\\'t\" : \"would not\",\n",
    "\t\t\t\t\"don\\'t\" : \"do not\",\n",
    "\t\t\t\t\"doesn\\'t\" : \"does not\",\n",
    "\t\t\t\t\"didn\\'t\" : \"did not\",\n",
    "\t\t\t\t\"can\\'t\" : \"can not\",\n",
    "\t\t\t\t\"couldn\\'t\" : \"could not\",\n",
    "\t\t\t\t\"shouldn\\'t\" : \"should not\",\n",
    "\t\t\t\t\"mightn\\'t\" : \"might not\",\n",
    "\t\t\t\t\"mustn\\'t\" : \"must not\",\n",
    "\t\t\t\t\"shan\\'t\" : \"shall not\",\n",
    "\t\t\t\t\"ain\\'t\" : \"am not\"}\n",
    "\t\n",
    "\t\tneg_expand_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\t\ttweets = tweets.apply(negation_expand, args=(neg_expand_pattern, negations_dic))\n",
    "\t\n",
    "\t#Remove punctuation\n",
    "\tif text_options['punctuation_remove'] is True:\n",
    "\t\ttweets = tweets.apply(punctuation_remove)\n",
    "\n",
    "\t#Remove metadata- hashtags, urls, mentions, unicode\n",
    "\tif text_options['metadata_remove'] is True:\n",
    "\t\ttweets = tweets.apply(metadata_remove)\n",
    "\n",
    "\t#Remove emojis from tweets\n",
    "\tif text_options['emoji_remove'] is True:\n",
    "\t\ttweets = tweets.apply(emoji_remove)\n",
    "\n",
    "\t#Remove digits\n",
    "\tif text_options['digits_remove'] is True:\n",
    "\t\ttweets = tweets.apply(digits_remove)\n",
    "\t\n",
    "\t#Mark negations\n",
    "\tif text_options['negation_mark'] is True:\n",
    "\t\tneg_words = ['not', 'never', 'no', 'nothing', 'noone', 'nowhere', 'none',\n",
    "\t\t\t\t'isnt', 'arent', 'wasnt', 'werent', 'havent', 'hasnt', 'hadnt',\n",
    "\t\t\t\t'wont', 'wouldnt', 'dont', 'doesnt', 'didnt', 'cant', 'couldnt',\n",
    "\t\t\t\t'shouldnt', 'mightnt', 'mustnt', 'shant', 'aint']\n",
    "\t\tneg_mark_pattern = re.compile(r'\\b(' + '|'.join(neg_words) + r')\\b')\n",
    "\t\ttweets = tweets.apply(negation_marking, args=(neg_mark_pattern,))\n",
    "\t\n",
    "\t#Normalization\n",
    "\tif text_options['normalize'] is True:\n",
    "\t\trepeat_pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "\t\ttweets = tweets.apply(normalize_text, args=(repeat_pattern,))\n",
    "\n",
    "\t#Remove stopwords: done before stemming and after negation marking (stemmer stems stopwords, if done before negation marking, some negation words removed)\n",
    "\tif text_options['stopwords_remove'] is True:\n",
    "\t\ttweets = tweets.apply(stopwords_remove)\n",
    "\n",
    "\t#Stemming. Note: will convert to lowercase and also stem stopwords (such as 'was' to 'wa')\n",
    "\tif text_options['stemming'] is True:\n",
    "\t\tps = PorterStemmer()\n",
    "\t\ttweets = tweets.apply(stemming_apply, args=(ps,))\n",
    "\n",
    "\t#Lowercasing of text\n",
    "\tif text_options['lower'] is True:\n",
    "\t\ttweets = tweets.str.lower()\n",
    "\n",
    "\treturn tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 possible preprocessing steps:\n",
    "1. *'metadata_remove'*: True or False. Metadata includes hashtag, url's, mentions, and unicodes. Emojis and other metadata are translated by default.\n",
    "2. *'punctuation_remove'*: True if remove from text, else False\n",
    "3. *'negation_expand'*: True if expand negation words, else False\n",
    "4. *'digits_remove'*: True if remove digits (0-9), else False\n",
    "5. *'negation_mark'*: True if negation marking applied to tokens, else False\n",
    "6. *'normalize'*: True for text normalization, else False\n",
    "7. *'stopwords_remove'*: True for removal of stop words, else False\n",
    "8. *'stemming'*: True if stemming applied, else False\n",
    "9. *'lower'*: True for lowercasing tweet text, else False\n",
    "10. *'emoji_remove'*: True to remove emojis from text, else False\n",
    "\n",
    "Options are all True by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class NLP_transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 metadata_remove=True, emoji_remove=True, negation_expand=True, punctuation_remove=True, \n",
    "                 digits_remove=True, negation_mark=True, normalize=True, stemming=True, \n",
    "                 stopwords_remove=True, lower=True):\n",
    "        \"\"\"\n",
    "        A custom Transformer that takes in text column of dataframe and transforms to clean text.\n",
    "        Arguments are text options specified above.\n",
    "        \"\"\"\n",
    "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
    "        values.pop('self')\n",
    "        self.text_options = {}\n",
    "        for arg, val in values.items():\n",
    "            self.text_options[arg] = val\n",
    "    def transform(self, X, y=None):\n",
    "        return preprocess(X, self.text_options)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "    ('preprocess', NLP_transformer()), \n",
    "    ('vectorizer', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', ClassifierPipeline())\n",
    "    ]\n",
    ")\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score),\n",
    "           'Brier': 'brier_score_loss', 'f1-score': make_scorer(f1_score),\n",
    "           'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score)}\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'preprocess__metadata_remove': [False, True],\n",
    "        'preprocess__emoji_remove': [False, True],\n",
    "        'preprocess__punctuation_remove': [False, True],\n",
    "        'preprocess__negation_expand': [False, True],\n",
    "        'preprocess__digits_remove': [False, True],\n",
    "        'preprocess__negation_mark': [False, True],\n",
    "        'preprocess__normalize': [False, True],\n",
    "        'preprocess__stopwords_remove': [False, True],\n",
    "        'preprocess__stemming': [False, True],\n",
    "        'preprocess__lower': [False, True],\n",
    "        'clf__estimator': [LogisticRegression()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'tfidf__use_idf': [False, True],\n",
    "        'clf__estimator__penalty': ['l2'],\n",
    "        'clf__estimator__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    },\n",
    "    {\n",
    "        'preprocess__metadata_remove': [False, True],\n",
    "        'preprocess__emoji_remove': [False, True],\n",
    "        'preprocess__punctuation_remove': [False, True],\n",
    "        'preprocess__negation_expand': [False, True],\n",
    "        'preprocess__digits_remove': [False, True],\n",
    "        'preprocess__negation_mark': [False, True],\n",
    "        'preprocess__normalize': [False, True],\n",
    "        'preprocess__stopwords_remove': [False, True],\n",
    "        'preprocess__stemming': [False, True],\n",
    "        'preprocess__lower': [False, True],\n",
    "        'clf__estimator': [LinearSVC()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'clf__estimator__penalty': ['l2'],\n",
    "        'clf__estimator__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    },\n",
    "    {\n",
    "        'preprocess__metadata_remove': [False, True],\n",
    "        'preprocess__emoji_remove': [False, True],\n",
    "        'preprocess__punctuation_remove': [False, True],\n",
    "        'preprocess__negation_expand': [False, True],\n",
    "        'preprocess__digits_remove': [False, True],\n",
    "        'preprocess__negation_mark': [False, True],\n",
    "        'preprocess__normalize': [False, True],\n",
    "        'preprocess__stopwords_remove': [False, True],\n",
    "        'preprocess__stemming': [False, True],\n",
    "        'preprocess__lower': [False, True],\n",
    "        'clf__estimator': [BernoulliNB()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'clf__estimator__alpha': np.logspace(-4, 4, 5),\n",
    "    },\n",
    "    {\n",
    "        'preprocess__metadata_remove': [False, True],\n",
    "        'preprocess__emoji_remove': [False, True],\n",
    "        'preprocess__punctuation_remove': [False, True],\n",
    "        'preprocess__negation_expand': [False, True],\n",
    "        'preprocess__digits_remove': [False, True],\n",
    "        'preprocess__negation_mark': [False, True],\n",
    "        'preprocess__normalize': [False, True],\n",
    "        'preprocess__stopwords_remove': [False, True],\n",
    "        'preprocess__stemming': [False, True],\n",
    "        'preprocess__lower': [False, True],\n",
    "        'clf__estimator': [RandomForestClassifier()],\n",
    "        'vectorizer__max_features': np.arange(1000,10000,100),\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__stop_words': [None],\n",
    "        'clf__estimator__n_estimators': [200, 500],\n",
    "        'clf__estimator__max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'clf__estimator__max_depth': [4,5,6,7,8],\n",
    "        'clf__estimator__criterion': ['gini', 'entropy'],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.907):\n",
      "{'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'clf__estimator__C': 1, 'clf__estimator__penalty': 'l2', 'preprocess__digits': False, 'preprocess__emoji': False, 'preprocess__lower': False, 'preprocess__metadata': 1, 'preprocess__negation_expand': False, 'preprocess__normalize': False, 'preprocess__punctuation': False, 'preprocess__stemming': False, 'preprocess__stopwords': False, 'tfidf__use_idf': False, 'vectorizer__max_features': 3500, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0403512 , 0.03981028, 0.03670082, 0.03957047, 0.03650131,\n",
       "        0.0398365 , 0.03961735, 0.03921094, 0.04045658, 0.03748951,\n",
       "        0.04044547, 0.04018364, 0.04098425, 0.03730659, 0.03902502,\n",
       "        0.03624907, 0.03958673, 0.03570094, 0.04386249, 0.0398757 ,\n",
       "        0.03998594, 0.03855577, 0.03800268, 0.03647332, 0.04157043,\n",
       "        0.03937721, 0.03979721, 0.03822179, 0.03811841, 0.03595705,\n",
       "        0.03901234, 0.03559742, 0.04003134, 0.03902564, 0.03748217,\n",
       "        0.0406796 , 0.03680849, 0.03754802, 0.03798261, 0.0407989 ,\n",
       "        0.03781343, 0.03967919, 0.04260292, 0.03512135, 0.03941388,\n",
       "        0.03880229, 0.04035039, 0.03936143, 0.03674197, 0.03978357,\n",
       "        0.03875518, 0.03802009, 0.04066854, 0.03805256, 0.03836823,\n",
       "        0.03971586, 0.03804245, 0.03980861, 0.03775954, 0.04282408,\n",
       "        0.03944077, 0.04122005, 0.04133177, 0.03642893, 0.03982892,\n",
       "        0.03559251, 0.03715873, 0.03926282, 0.03975039, 0.04234357,\n",
       "        0.04080062, 0.03594041, 0.03828173, 0.03879776, 0.03940325,\n",
       "        0.03751979, 0.03803577, 0.03850713, 0.03957324, 0.03699155,\n",
       "        0.03776393, 0.03866186, 0.03939295, 0.03992524, 0.03786621,\n",
       "        0.03680425, 0.03829765, 0.0382647 , 0.03842659, 0.04279923,\n",
       "        0.0402822 , 0.03911381, 0.03871493, 0.03702178, 0.03976336,\n",
       "        0.04182925, 0.03808813, 0.04378543, 0.03827577, 0.03633113,\n",
       "        0.03773737, 0.03997064, 0.03648276, 0.03942971, 0.04068651,\n",
       "        0.03804369, 0.04167461, 0.03647237, 0.04230943, 0.04065528,\n",
       "        0.04101143, 0.03613038, 0.03663888, 0.03843827, 0.03921676,\n",
       "        0.03654895, 0.04072237, 0.03950624, 0.03902955, 0.03684449,\n",
       "        0.03915763, 0.03842039, 0.03621049, 0.0387321 , 0.03968   ,\n",
       "        0.03696909, 0.04044189, 0.03633299, 0.03708081, 0.03821783,\n",
       "        0.04041147, 0.03842969, 0.04274411, 0.03607984, 0.03834429,\n",
       "        0.03726602, 0.03989382, 0.0381454 , 0.03649831, 0.03887396,\n",
       "        0.04294114, 0.040027  , 0.043785  , 0.03630371, 0.03977141,\n",
       "        0.03748193, 0.03789501, 0.04019089, 0.03922319, 0.03712211,\n",
       "        0.03801947, 0.03848338, 0.03626442, 0.03713865, 0.03722653,\n",
       "        0.03776064, 0.03912582, 0.0378046 , 0.03843632, 0.03908896,\n",
       "        0.03635187, 0.03568344, 0.0401    , 0.0381206 , 0.04185185,\n",
       "        0.03742366, 0.03562508, 0.03898659, 0.03963413, 0.03654766,\n",
       "        0.03481755, 0.03848691, 0.03893247, 0.04146352, 0.03607907,\n",
       "        0.03705916, 0.0382441 , 0.0376224 , 0.03912668, 0.03903241,\n",
       "        0.03576941, 0.04034667, 0.03877831, 0.03888273, 0.04158597,\n",
       "        0.03778071, 0.04208307, 0.03805494, 0.03658929, 0.03734164,\n",
       "        0.04125004, 0.04009933, 0.03519359, 0.04042974, 0.03405738,\n",
       "        0.040204  , 0.03739319, 0.03931003, 0.03727217, 0.03879976,\n",
       "        0.03814034, 0.03656902, 0.04036489, 0.03892412, 0.03811884,\n",
       "        0.04129391, 0.04057946, 0.03906779, 0.03972588, 0.038519  ,\n",
       "        0.04053578, 0.03824844, 0.04099135, 0.03966751, 0.03871899,\n",
       "        0.04032321, 0.04173269, 0.03924217, 0.04135909, 0.03810935,\n",
       "        0.03846359, 0.03688226, 0.04000835, 0.04115596, 0.03733001,\n",
       "        0.03873625, 0.03586006, 0.04267793, 0.03814449, 0.03877621,\n",
       "        0.03966703, 0.03934317, 0.04301209, 0.03889208, 0.03695669,\n",
       "        0.03934875, 0.04051881, 0.03818955, 0.03629074, 0.0363492 ,\n",
       "        0.03770533, 0.03703885, 0.04054928, 0.03913455, 0.03626556,\n",
       "        0.04099636, 0.04012251, 0.03702826, 0.03631206, 0.03845153,\n",
       "        0.03954535, 0.03957586, 0.03764544, 0.04120002, 0.03721099,\n",
       "        0.042097  , 0.03617849, 0.03992171, 0.03691487, 0.03802819,\n",
       "        0.03867917, 0.03996172, 0.04272103, 0.03791003, 0.03762083,\n",
       "        0.03562598, 0.03726268, 0.03869257, 0.04369502, 0.03862872,\n",
       "        0.03594537, 0.03908248, 0.03611865, 0.03718634, 0.03776951,\n",
       "        0.03611674, 0.03894815, 0.03920045, 0.04147182, 0.04067483,\n",
       "        0.03609514, 0.03599191, 0.03993273, 0.03704982, 0.03615556,\n",
       "        0.04002924, 0.03830447, 0.04130654, 0.03849201, 0.03693151,\n",
       "        0.04179978, 0.03999448, 0.03824029, 0.04347572, 0.03807182,\n",
       "        0.04029646, 0.03627563, 0.0409184 , 0.03921056, 0.03761625,\n",
       "        0.04064326, 0.03942027, 0.04065065, 0.04205265, 0.04276338,\n",
       "        0.03922839, 0.03852444, 0.0433279 , 0.04033847, 0.03771672,\n",
       "        0.04056196, 0.04000521, 0.04158602, 0.03989553, 0.03818283,\n",
       "        0.04028826, 0.03977671, 0.03573284, 0.04258223, 0.03993406,\n",
       "        0.03774981, 0.03729072, 0.03795996, 0.03795824, 0.04174137,\n",
       "        0.03906994, 0.03661165, 0.04019613, 0.04000273, 0.04041271,\n",
       "        0.03955545, 0.03982015, 0.03693366, 0.03634052, 0.0388133 ,\n",
       "        0.0419538 , 0.0360538 , 0.04033122, 0.0398334 , 0.03924904,\n",
       "        0.04187083, 0.03725233, 0.03935909, 0.03561144, 0.03629122,\n",
       "        0.04097004, 0.03901405, 0.03956642, 0.04320312, 0.03688941,\n",
       "        0.04174924, 0.03881717, 0.04029231, 0.03668599, 0.03783021,\n",
       "        0.03702216, 0.03807664, 0.03848944, 0.03730707, 0.03598814,\n",
       "        0.03826547, 0.04112225, 0.03642988, 0.04549541, 0.04321094,\n",
       "        0.03600335, 0.04378738, 0.03676457, 0.0409658 , 0.04008861,\n",
       "        0.03655429, 0.04020491, 0.03756056, 0.03740654, 0.03891749,\n",
       "        0.03848472, 0.04103665, 0.04122777, 0.03776975, 0.04237161,\n",
       "        0.04067879, 0.03572278, 0.03879442, 0.04268818, 0.03692183,\n",
       "        0.0396399 , 0.03756056, 0.03854327, 0.03881235, 0.04104099,\n",
       "        0.04201908, 0.0387269 , 0.03910918, 0.03948236, 0.04021807,\n",
       "        0.0388073 , 0.04186225, 0.03939967, 0.03738837, 0.03870392,\n",
       "        0.03860021, 0.03801265, 0.03802772, 0.03859048, 0.0389245 ,\n",
       "        0.04068046, 0.03740311, 0.03902097, 0.04224768, 0.03850675,\n",
       "        0.03772569, 0.03647575, 0.0379034 , 0.03954754, 0.03611951,\n",
       "        0.0384726 , 0.03943672, 0.03926425, 0.03956871, 0.04154811,\n",
       "        0.03807893, 0.03548436, 0.04008102, 0.03899846, 0.039325  ,\n",
       "        0.03973756, 0.03623919, 0.03967862, 0.03767643, 0.0393889 ,\n",
       "        0.03950033, 0.03971062, 0.03588042, 0.0405273 , 0.0381752 ,\n",
       "        0.03817239, 0.04065151, 0.0392673 , 0.03755116, 0.03790064,\n",
       "        0.04129057, 0.03992338, 0.04054093, 0.03906493, 0.03975444,\n",
       "        0.03860812, 0.03755374, 0.04030242, 0.03677545, 0.04133477,\n",
       "        0.04224868, 0.03871331, 0.03823657, 0.04198289, 0.04086022,\n",
       "        0.03884454, 0.04052114, 0.04005127, 0.03899689, 0.04164619,\n",
       "        0.04021006, 0.04031582, 0.03925261, 0.04528818, 0.03766685,\n",
       "        0.04015932, 0.04136262, 0.03984942, 0.03885241, 0.03926759,\n",
       "        0.04012356, 0.03916111, 0.03684683, 0.0403471 , 0.03744507,\n",
       "        0.0365428 , 0.04062338, 0.03899436, 0.04146247, 0.03830457,\n",
       "        0.03974609, 0.0413641 , 0.03715386, 0.04137421, 0.03633995,\n",
       "        0.03766489, 0.03898802, 0.03895402, 0.03770232, 0.03779593,\n",
       "        0.03584275, 0.04142365, 0.03747578, 0.03942723, 0.03859921,\n",
       "        0.03835201, 0.03957009, 0.0402863 , 0.03848748, 0.03998384,\n",
       "        0.03835287, 0.03900127, 0.03814111, 0.04059048, 0.03895288,\n",
       "        0.03955736, 0.03904576, 0.03722582, 0.03595772, 0.03704   ,\n",
       "        0.04092679, 0.03891263]),\n",
       " 'std_fit_time': array([0.00318019, 0.00536425, 0.00127495, 0.00454787, 0.001506  ,\n",
       "        0.00517852, 0.00503428, 0.00374173, 0.00302125, 0.00302407,\n",
       "        0.00551022, 0.00480518, 0.0033583 , 0.00345346, 0.00578814,\n",
       "        0.00032941, 0.00342436, 0.0003835 , 0.00421022, 0.00440214,\n",
       "        0.0037891 , 0.00373472, 0.00438905, 0.00043376, 0.00536832,\n",
       "        0.00381562, 0.00430889, 0.00421564, 0.00400329, 0.00074374,\n",
       "        0.00425301, 0.0006905 , 0.00564653, 0.00390836, 0.00282114,\n",
       "        0.00619449, 0.00240923, 0.00210601, 0.00228653, 0.00415167,\n",
       "        0.00236964, 0.00355317, 0.0052151 , 0.00067404, 0.00400337,\n",
       "        0.00156566, 0.00471524, 0.00409014, 0.00506636, 0.00454531,\n",
       "        0.00335438, 0.00416771, 0.0059476 , 0.00476734, 0.00474812,\n",
       "        0.00462683, 0.00380168, 0.00587539, 0.00255933, 0.00470652,\n",
       "        0.00504846, 0.00492499, 0.00451148, 0.00048333, 0.0031638 ,\n",
       "        0.0033319 , 0.00344435, 0.00360158, 0.00456742, 0.00622717,\n",
       "        0.00537399, 0.00042191, 0.0022909 , 0.00350598, 0.00470792,\n",
       "        0.00305772, 0.00344853, 0.00416534, 0.00454118, 0.00205869,\n",
       "        0.00248975, 0.00400752, 0.00419903, 0.00481057, 0.00451771,\n",
       "        0.00343328, 0.00526933, 0.00444247, 0.0036641 , 0.00513346,\n",
       "        0.00447518, 0.00504136, 0.00422304, 0.00175495, 0.00456251,\n",
       "        0.0055163 , 0.00421197, 0.00904737, 0.00462853, 0.00097265,\n",
       "        0.00253262, 0.00404265, 0.00070781, 0.00438771, 0.00596347,\n",
       "        0.00304454, 0.00439447, 0.00086734, 0.00409069, 0.0057613 ,\n",
       "        0.0041096 , 0.000737  , 0.00159143, 0.00399765, 0.00368739,\n",
       "        0.00068544, 0.00389665, 0.00407148, 0.00409321, 0.00254472,\n",
       "        0.0042256 , 0.00429214, 0.0012869 , 0.00434757, 0.00437811,\n",
       "        0.00189607, 0.00658752, 0.00116731, 0.00268851, 0.00555302,\n",
       "        0.00550993, 0.00320378, 0.00521465, 0.00047226, 0.00454039,\n",
       "        0.00454052, 0.00402205, 0.00286873, 0.00097517, 0.00298177,\n",
       "        0.00648857, 0.00662207, 0.00645139, 0.00144592, 0.00311695,\n",
       "        0.00228251, 0.00454905, 0.00439363, 0.00494834, 0.00284838,\n",
       "        0.00383491, 0.00280012, 0.0007964 , 0.00194977, 0.00220934,\n",
       "        0.00409417, 0.00427352, 0.00302397, 0.00537535, 0.00406959,\n",
       "        0.00092336, 0.0010749 , 0.0051168 , 0.00548999, 0.00644676,\n",
       "        0.00159322, 0.00060188, 0.00465734, 0.00441056, 0.00303385,\n",
       "        0.00360057, 0.00374813, 0.00320831, 0.00475298, 0.00105165,\n",
       "        0.00145247, 0.00433859, 0.00259168, 0.00459441, 0.00367386,\n",
       "        0.00419524, 0.00583855, 0.00370881, 0.00212851, 0.00742758,\n",
       "        0.00241428, 0.00424738, 0.0031152 , 0.00108348, 0.00293082,\n",
       "        0.0053416 , 0.00437616, 0.00189376, 0.00378465, 0.00299316,\n",
       "        0.00674827, 0.00297718, 0.00271538, 0.00134878, 0.00383698,\n",
       "        0.00494649, 0.0047046 , 0.00520958, 0.00556085, 0.00486046,\n",
       "        0.00502651, 0.0057524 , 0.00489723, 0.0045838 , 0.00676382,\n",
       "        0.00408483, 0.00375939, 0.00534945, 0.00750228, 0.00427405,\n",
       "        0.0058367 , 0.00457605, 0.00432612, 0.00744151, 0.00404534,\n",
       "        0.00414367, 0.00121926, 0.00443843, 0.00584822, 0.0028406 ,\n",
       "        0.00397493, 0.00087558, 0.00584356, 0.00481472, 0.0041004 ,\n",
       "        0.00435932, 0.004531  , 0.0031588 , 0.00472456, 0.00240714,\n",
       "        0.00419847, 0.00561048, 0.00457688, 0.00142344, 0.00081492,\n",
       "        0.00321452, 0.00118576, 0.00555417, 0.00593103, 0.00097912,\n",
       "        0.00530975, 0.00499723, 0.00189931, 0.0042784 , 0.00449634,\n",
       "        0.00328954, 0.00528076, 0.00311007, 0.00521275, 0.00480062,\n",
       "        0.00612869, 0.00078127, 0.00405349, 0.00194774, 0.00225065,\n",
       "        0.00661686, 0.00580864, 0.00500092, 0.00459528, 0.00454036,\n",
       "        0.00115418, 0.00329592, 0.00251461, 0.00367521, 0.00388022,\n",
       "        0.00084429, 0.00492937, 0.0006273 , 0.00159747, 0.00220475,\n",
       "        0.00052553, 0.00744184, 0.0047718 , 0.00950718, 0.00528749,\n",
       "        0.00155039, 0.00090427, 0.00846078, 0.00238772, 0.00108988,\n",
       "        0.0040604 , 0.00339336, 0.00532025, 0.00238255, 0.00135304,\n",
       "        0.01007929, 0.00477927, 0.0044318 , 0.00768342, 0.00252325,\n",
       "        0.00427323, 0.00081555, 0.00531185, 0.00435842, 0.00270203,\n",
       "        0.00438052, 0.00451475, 0.00655886, 0.00552527, 0.00487396,\n",
       "        0.00379484, 0.0037291 , 0.00508971, 0.00470933, 0.00221613,\n",
       "        0.00420934, 0.00619932, 0.00467392, 0.00412528, 0.00380183,\n",
       "        0.00463355, 0.00466193, 0.00061926, 0.00513283, 0.00434444,\n",
       "        0.00486403, 0.0020214 , 0.00459216, 0.00273617, 0.00458672,\n",
       "        0.00347085, 0.00124429, 0.00453527, 0.00443937, 0.00456344,\n",
       "        0.00222582, 0.00591519, 0.00207797, 0.00101078, 0.00449725,\n",
       "        0.00580228, 0.00037151, 0.00517833, 0.00618208, 0.00405068,\n",
       "        0.01213135, 0.00256416, 0.00380903, 0.00088043, 0.0008364 ,\n",
       "        0.00525976, 0.00422169, 0.00432829, 0.00368425, 0.00216344,\n",
       "        0.00388246, 0.00455751, 0.00475033, 0.00078917, 0.00250022,\n",
       "        0.00089563, 0.00427784, 0.00426718, 0.00244917, 0.0009942 ,\n",
       "        0.00242173, 0.00603462, 0.00056852, 0.00729083, 0.00626585,\n",
       "        0.00050927, 0.00439604, 0.00392691, 0.00652799, 0.0049004 ,\n",
       "        0.00079702, 0.00469464, 0.00172618, 0.00544911, 0.00357501,\n",
       "        0.00357139, 0.00413577, 0.00496299, 0.00367796, 0.00794951,\n",
       "        0.00514707, 0.00053303, 0.00445609, 0.00671046, 0.00087044,\n",
       "        0.00402363, 0.00213846, 0.00427625, 0.00443956, 0.00434715,\n",
       "        0.00612222, 0.00396836, 0.00436446, 0.00396194, 0.00405323,\n",
       "        0.00315933, 0.00436727, 0.00472047, 0.00180207, 0.00467967,\n",
       "        0.0026353 , 0.00434565, 0.00301243, 0.00421014, 0.00238238,\n",
       "        0.00405367, 0.00306285, 0.00480802, 0.00776039, 0.00386586,\n",
       "        0.0042426 , 0.00346927, 0.00456284, 0.00400522, 0.00080777,\n",
       "        0.00429275, 0.00373026, 0.00466782, 0.00613745, 0.00474897,\n",
       "        0.00456998, 0.00415756, 0.00481326, 0.00341778, 0.00318096,\n",
       "        0.00450918, 0.00109199, 0.00430191, 0.00238449, 0.00476429,\n",
       "        0.00704128, 0.00464767, 0.00031573, 0.0058899 , 0.00434514,\n",
       "        0.00452055, 0.00519328, 0.00400325, 0.00259583, 0.00361931,\n",
       "        0.0047145 , 0.00474617, 0.00591045, 0.00426159, 0.00426988,\n",
       "        0.00465901, 0.00339853, 0.0062912 , 0.00129497, 0.00575824,\n",
       "        0.00430491, 0.00571947, 0.00426181, 0.00577736, 0.00429543,\n",
       "        0.00380453, 0.00542126, 0.00407437, 0.00401627, 0.00342523,\n",
       "        0.00532374, 0.00549512, 0.00473151, 0.01244713, 0.00425275,\n",
       "        0.00291875, 0.00387599, 0.00413197, 0.00477188, 0.0038848 ,\n",
       "        0.00455678, 0.00613891, 0.00448623, 0.00857855, 0.00352671,\n",
       "        0.00163363, 0.00473807, 0.00437075, 0.00426709, 0.00217086,\n",
       "        0.0059747 , 0.00709756, 0.00269502, 0.00409529, 0.0014299 ,\n",
       "        0.00235316, 0.00315166, 0.00637896, 0.00162532, 0.0027389 ,\n",
       "        0.00071073, 0.00585785, 0.00475737, 0.0047114 , 0.00445353,\n",
       "        0.00294139, 0.00428636, 0.00701051, 0.00383333, 0.00352003,\n",
       "        0.00265296, 0.00337317, 0.00476938, 0.0068683 , 0.00703044,\n",
       "        0.00506382, 0.00420309, 0.00217878, 0.00070715, 0.00221571,\n",
       "        0.00574089, 0.00455116]),\n",
       " 'mean_score_time': array([0.0401195 , 0.04022865, 0.0377368 , 0.03807206, 0.04135342,\n",
       "        0.03945584, 0.03855877, 0.03790154, 0.0390614 , 0.04190817,\n",
       "        0.03965845, 0.03724637, 0.04127069, 0.03661261, 0.04114366,\n",
       "        0.03661294, 0.04053984, 0.03912778, 0.04080753, 0.03751845,\n",
       "        0.03847103, 0.03729606, 0.03708134, 0.03899765, 0.04285583,\n",
       "        0.03767271, 0.04092426, 0.03985443, 0.03723655, 0.03591332,\n",
       "        0.03831296, 0.04105444, 0.03691525, 0.03716316, 0.03844981,\n",
       "        0.04005218, 0.03653803, 0.0368669 , 0.03783054, 0.0368381 ,\n",
       "        0.03673716, 0.03706055, 0.04410443, 0.03651166, 0.03683529,\n",
       "        0.03952584, 0.03659201, 0.03987913, 0.03606229, 0.04145017,\n",
       "        0.04165478, 0.03654108, 0.03765726, 0.03778901, 0.03828378,\n",
       "        0.04050879, 0.03743024, 0.04088826, 0.0372303 , 0.03683791,\n",
       "        0.04103117, 0.03915195, 0.03787794, 0.03859048, 0.03652697,\n",
       "        0.03642583, 0.03856373, 0.04099212, 0.03680391, 0.03923531,\n",
       "        0.03694868, 0.03866162, 0.03927035, 0.03847322, 0.03806181,\n",
       "        0.04135923, 0.03613782, 0.03774819, 0.03861384, 0.03772154,\n",
       "        0.03771009, 0.03614936, 0.03901896, 0.04115376, 0.0367702 ,\n",
       "        0.03566942, 0.04062815, 0.03963966, 0.03855157, 0.03762717,\n",
       "        0.040377  , 0.0393877 , 0.03782129, 0.0397048 , 0.0383975 ,\n",
       "        0.03949227, 0.03742766, 0.03905177, 0.0369863 , 0.03828802,\n",
       "        0.04002666, 0.03996415, 0.04009609, 0.04135642, 0.03862262,\n",
       "        0.03856997, 0.03917289, 0.03626728, 0.03743215, 0.04017596,\n",
       "        0.03688188, 0.03803658, 0.03895907, 0.03944802, 0.03955789,\n",
       "        0.03871822, 0.0384851 , 0.03983722, 0.03830266, 0.03726187,\n",
       "        0.03976612, 0.03670087, 0.03992362, 0.03658895, 0.04057345,\n",
       "        0.03724632, 0.03780293, 0.03684163, 0.03910985, 0.03644805,\n",
       "        0.03967013, 0.03735161, 0.0408349 , 0.03818913, 0.03940043,\n",
       "        0.04043031, 0.03791146, 0.03689919, 0.04006567, 0.03848453,\n",
       "        0.03802528, 0.03694654, 0.04053426, 0.03947644, 0.03992624,\n",
       "        0.04231648, 0.0365397 , 0.03958054, 0.04151716, 0.03723912,\n",
       "        0.03661127, 0.03923297, 0.04017549, 0.03995028, 0.03939757,\n",
       "        0.03654647, 0.03876042, 0.03768907, 0.04127722, 0.03871655,\n",
       "        0.03766909, 0.03645048, 0.03952699, 0.03864627, 0.03877382,\n",
       "        0.03827677, 0.03682127, 0.04003625, 0.03953738, 0.04041681,\n",
       "        0.03844719, 0.041996  , 0.04121532, 0.03841939, 0.0374434 ,\n",
       "        0.03994098, 0.0370327 , 0.03981671, 0.03702607, 0.04054117,\n",
       "        0.03696728, 0.0397203 , 0.03757472, 0.03817511, 0.03897648,\n",
       "        0.03635077, 0.03928194, 0.03723426, 0.0436285 , 0.03905859,\n",
       "        0.03682256, 0.03947368, 0.03676305, 0.040134  , 0.03637018,\n",
       "        0.03996749, 0.03653498, 0.03881631, 0.03773489, 0.03963943,\n",
       "        0.03695445, 0.04065132, 0.03670192, 0.03847723, 0.04160328,\n",
       "        0.04375801, 0.03873277, 0.03916178, 0.03689256, 0.03944654,\n",
       "        0.03866696, 0.03745384, 0.03841004, 0.03711267, 0.03854361,\n",
       "        0.03756418, 0.03949485, 0.03707442, 0.04159946, 0.03807158,\n",
       "        0.0401823 , 0.03588505, 0.04057512, 0.03973989, 0.03686218,\n",
       "        0.04027972, 0.03681331, 0.04166751, 0.03928967, 0.03704157,\n",
       "        0.03934255, 0.03759074, 0.03875608, 0.03727703, 0.0390739 ,\n",
       "        0.03647213, 0.04084115, 0.03851824, 0.03711834, 0.03998618,\n",
       "        0.03715086, 0.0438561 , 0.03761225, 0.04025183, 0.03963895,\n",
       "        0.03734264, 0.03857732, 0.03697867, 0.04186296, 0.03718486,\n",
       "        0.04042583, 0.03677683, 0.03886328, 0.03684931, 0.03940086,\n",
       "        0.04068718, 0.03988018, 0.04074516, 0.0434155 , 0.036725  ,\n",
       "        0.0376442 , 0.03947973, 0.04140868, 0.04023433, 0.03684106,\n",
       "        0.03720794, 0.03843188, 0.03979325, 0.04089084, 0.03856802,\n",
       "        0.03785977, 0.03686123, 0.03997288, 0.03704042, 0.03812943,\n",
       "        0.03717408, 0.04020448, 0.03710618, 0.04031892, 0.03983059,\n",
       "        0.04176674, 0.03716326, 0.0378356 , 0.03656325, 0.0389421 ,\n",
       "        0.03853383, 0.037852  , 0.03938689, 0.04272318, 0.03951898,\n",
       "        0.04056749, 0.03824115, 0.03895941, 0.03865724, 0.0370657 ,\n",
       "        0.04422407, 0.03855267, 0.04133673, 0.04054089, 0.03729911,\n",
       "        0.04134655, 0.03718381, 0.03870068, 0.03635492, 0.04055805,\n",
       "        0.0411325 , 0.03697867, 0.04107666, 0.03907251, 0.03973827,\n",
       "        0.03800044, 0.03932648, 0.03902645, 0.03634324, 0.03958917,\n",
       "        0.03686385, 0.0385777 , 0.03778696, 0.03812227, 0.03671961,\n",
       "        0.03675566, 0.03934979, 0.03786836, 0.03920989, 0.03693976,\n",
       "        0.03902335, 0.03727593, 0.04144726, 0.0418386 , 0.04130578,\n",
       "        0.03894672, 0.04036031, 0.03734012, 0.03809791, 0.03687897,\n",
       "        0.03819122, 0.03964062, 0.0378715 , 0.04038472, 0.03652148,\n",
       "        0.04172721, 0.03753695, 0.0402226 , 0.03602324, 0.03810134,\n",
       "        0.04200053, 0.04212656, 0.03880033, 0.03829513, 0.0397541 ,\n",
       "        0.04052887, 0.03897514, 0.0397047 , 0.04034257, 0.03868718,\n",
       "        0.03836284, 0.03759999, 0.04227538, 0.04211178, 0.0371099 ,\n",
       "        0.04144416, 0.0406209 , 0.04051843, 0.03959522, 0.03855176,\n",
       "        0.0382761 , 0.04146705, 0.0365375 , 0.04131145, 0.03667893,\n",
       "        0.04079056, 0.03761306, 0.03684549, 0.03664951, 0.04185214,\n",
       "        0.03686466, 0.03903747, 0.04285083, 0.03660221, 0.04062614,\n",
       "        0.03742585, 0.03875585, 0.03843651, 0.04157858, 0.04166312,\n",
       "        0.03695984, 0.04153175, 0.03917789, 0.03854108, 0.0381074 ,\n",
       "        0.04021358, 0.03744802, 0.03713732, 0.04084454, 0.0370399 ,\n",
       "        0.04004602, 0.03964114, 0.03677659, 0.03856592, 0.03792472,\n",
       "        0.03975868, 0.03721995, 0.03756757, 0.04085326, 0.03845339,\n",
       "        0.0365952 , 0.03924823, 0.037883  , 0.04063168, 0.03915958,\n",
       "        0.03689508, 0.03887129, 0.0370357 , 0.03833852, 0.04119334,\n",
       "        0.03762527, 0.03896732, 0.03951812, 0.03778396, 0.03969288,\n",
       "        0.03850746, 0.03612323, 0.04173441, 0.04045606, 0.04140139,\n",
       "        0.03793545, 0.03682871, 0.0392858 , 0.03948951, 0.03694558,\n",
       "        0.04062362, 0.03759995, 0.0392899 , 0.04091663, 0.03663731,\n",
       "        0.04190698, 0.03649745, 0.03881192, 0.03982067, 0.03703079,\n",
       "        0.03661737, 0.04144478, 0.04106665, 0.04028497, 0.03911552,\n",
       "        0.03754191, 0.03816338, 0.03692489, 0.04119925, 0.03888345,\n",
       "        0.04231801, 0.03822079, 0.03753705, 0.03834467, 0.03809509,\n",
       "        0.03755884, 0.04146338, 0.03636818, 0.04097757, 0.03783622,\n",
       "        0.0408433 , 0.0383049 , 0.03726854, 0.04014201, 0.03741422,\n",
       "        0.03906689, 0.03701491, 0.03856888, 0.03693242, 0.0412612 ,\n",
       "        0.03705754, 0.03874669, 0.03601403, 0.03935614, 0.04030395,\n",
       "        0.03809767, 0.03977399, 0.03682518, 0.03845344, 0.04122391,\n",
       "        0.03911457, 0.04198499, 0.03658781, 0.0415668 , 0.03666577,\n",
       "        0.0400497 , 0.03803673, 0.03799539, 0.03852506, 0.03884082,\n",
       "        0.03785839, 0.03862181, 0.03858204, 0.03762994, 0.03708339,\n",
       "        0.0379622 , 0.03754454, 0.04177117, 0.03719831, 0.03836517,\n",
       "        0.03981819, 0.03907323, 0.04086938, 0.0404892 , 0.04080009,\n",
       "        0.03745494, 0.03894811, 0.037184  , 0.04042392, 0.03748136,\n",
       "        0.03809309, 0.03536606]),\n",
       " 'std_score_time': array([0.00488655, 0.0056124 , 0.0012968 , 0.00229199, 0.01318894,\n",
       "        0.00482206, 0.00494786, 0.00237333, 0.00272859, 0.00900956,\n",
       "        0.00463262, 0.00155921, 0.00594129, 0.00108559, 0.00495329,\n",
       "        0.00103578, 0.00420165, 0.00337909, 0.00440761, 0.00163702,\n",
       "        0.00318159, 0.00103233, 0.00133162, 0.00448642, 0.00848807,\n",
       "        0.00172488, 0.00721439, 0.0046144 , 0.00145377, 0.0028355 ,\n",
       "        0.00350048, 0.0049228 , 0.00145981, 0.00073528, 0.00323402,\n",
       "        0.00416697, 0.00096692, 0.00115333, 0.00409009, 0.0011807 ,\n",
       "        0.00193031, 0.00122011, 0.00574267, 0.00110716, 0.00110385,\n",
       "        0.00169882, 0.00126846, 0.00376827, 0.00128696, 0.00705534,\n",
       "        0.00792773, 0.0012357 , 0.00096718, 0.00272838, 0.00131526,\n",
       "        0.00806652, 0.00135596, 0.00835431, 0.00142278, 0.00148963,\n",
       "        0.00574266, 0.00611041, 0.00161992, 0.00297424, 0.00182569,\n",
       "        0.00304822, 0.00278346, 0.00749803, 0.00158801, 0.00464124,\n",
       "        0.00129187, 0.00304624, 0.00243559, 0.00326221, 0.0016821 ,\n",
       "        0.00391315, 0.00187512, 0.00418326, 0.00413332, 0.00193707,\n",
       "        0.00123297, 0.00133706, 0.00175914, 0.00698911, 0.00076246,\n",
       "        0.00129318, 0.00640762, 0.00734322, 0.0023336 , 0.00128914,\n",
       "        0.00660408, 0.00483059, 0.00169196, 0.00244637, 0.0012312 ,\n",
       "        0.00468886, 0.00171175, 0.002698  , 0.00129593, 0.00152213,\n",
       "        0.00548435, 0.00386274, 0.00493231, 0.01038604, 0.00344601,\n",
       "        0.00295618, 0.00443562, 0.0023567 , 0.0018126 , 0.00671631,\n",
       "        0.00128188, 0.00147513, 0.00409667, 0.00385454, 0.00520089,\n",
       "        0.00405043, 0.00213791, 0.00418884, 0.00432418, 0.00074619,\n",
       "        0.00644433, 0.0015719 , 0.0091464 , 0.00102923, 0.00607646,\n",
       "        0.00123343, 0.00200259, 0.00094552, 0.00311887, 0.00108681,\n",
       "        0.00304026, 0.00205587, 0.00819293, 0.00298182, 0.00667465,\n",
       "        0.0051744 , 0.00480036, 0.0013594 , 0.00429813, 0.00327967,\n",
       "        0.00262982, 0.00106956, 0.00449216, 0.0049904 , 0.00553896,\n",
       "        0.00898028, 0.00073987, 0.00639554, 0.00636078, 0.00051751,\n",
       "        0.00154962, 0.00302253, 0.00668817, 0.00502255, 0.00429291,\n",
       "        0.00087253, 0.00325225, 0.00220426, 0.00445729, 0.00439981,\n",
       "        0.00101261, 0.0029686 , 0.00628767, 0.00304346, 0.00340783,\n",
       "        0.0027225 , 0.00131171, 0.00393553, 0.00443406, 0.00730925,\n",
       "        0.00263062, 0.0078635 , 0.00518857, 0.00297893, 0.0014399 ,\n",
       "        0.0050936 , 0.00160055, 0.00398144, 0.00135809, 0.00333069,\n",
       "        0.00165991, 0.00454213, 0.00048431, 0.00328596, 0.00354979,\n",
       "        0.00117377, 0.00394863, 0.00127567, 0.00857421, 0.00482824,\n",
       "        0.00196866, 0.00285655, 0.00126947, 0.00215141, 0.00122248,\n",
       "        0.00470406, 0.00130807, 0.00234894, 0.00375157, 0.00569677,\n",
       "        0.00110726, 0.0083089 , 0.0014843 , 0.00195847, 0.00557508,\n",
       "        0.00827778, 0.00333261, 0.00519196, 0.00128352, 0.00501117,\n",
       "        0.00238242, 0.00163527, 0.00266771, 0.00140199, 0.00396617,\n",
       "        0.00108988, 0.00449475, 0.0014283 , 0.00725679, 0.00316131,\n",
       "        0.00618124, 0.00269738, 0.00603641, 0.00610207, 0.0012901 ,\n",
       "        0.00617501, 0.00107851, 0.00915605, 0.00289602, 0.00114403,\n",
       "        0.00583798, 0.00111649, 0.00310751, 0.00236472, 0.00566988,\n",
       "        0.00032949, 0.00450556, 0.00475106, 0.00064137, 0.00635243,\n",
       "        0.00080568, 0.01216888, 0.0014528 , 0.00566785, 0.00528679,\n",
       "        0.00125199, 0.00263955, 0.00134248, 0.00981223, 0.00115886,\n",
       "        0.0067489 , 0.00148055, 0.00414773, 0.0013982 , 0.00479899,\n",
       "        0.00629694, 0.00483013, 0.00368988, 0.0104342 , 0.00128753,\n",
       "        0.00164729, 0.00560878, 0.00889919, 0.00653014, 0.00106259,\n",
       "        0.00079993, 0.00255569, 0.00535025, 0.00903666, 0.00143994,\n",
       "        0.00191331, 0.00131712, 0.00372989, 0.00163158, 0.00505457,\n",
       "        0.00133347, 0.00475984, 0.00077128, 0.00621643, 0.00479999,\n",
       "        0.00738799, 0.0013112 , 0.00223638, 0.00108618, 0.00330321,\n",
       "        0.00534439, 0.00137023, 0.00343886, 0.0071185 , 0.00509749,\n",
       "        0.00750655, 0.00343575, 0.00563761, 0.00380059, 0.00134405,\n",
       "        0.00950459, 0.00310895, 0.00673879, 0.00619826, 0.00140951,\n",
       "        0.00914714, 0.00134043, 0.00530864, 0.00215234, 0.00503078,\n",
       "        0.00559338, 0.00118169, 0.00782114, 0.00486785, 0.00402283,\n",
       "        0.00216646, 0.00566297, 0.00355608, 0.00189049, 0.00526998,\n",
       "        0.0009104 , 0.00293522, 0.00245246, 0.0016116 , 0.0011456 ,\n",
       "        0.00122679, 0.00563178, 0.0022818 , 0.00640872, 0.00077999,\n",
       "        0.00235409, 0.00211317, 0.00882654, 0.00599935, 0.00862751,\n",
       "        0.00315117, 0.00667405, 0.00102753, 0.00202929, 0.00153175,\n",
       "        0.00343961, 0.00629958, 0.00086274, 0.0047774 , 0.00033268,\n",
       "        0.00977043, 0.00217787, 0.00535868, 0.0011173 , 0.00136488,\n",
       "        0.00641164, 0.00671406, 0.00240377, 0.00311164, 0.00511176,\n",
       "        0.00517242, 0.00215616, 0.00510864, 0.00580914, 0.00445189,\n",
       "        0.00284083, 0.00286574, 0.00869024, 0.00962551, 0.00135504,\n",
       "        0.00914494, 0.00740736, 0.00552493, 0.00481129, 0.00273467,\n",
       "        0.00428826, 0.00736102, 0.0009327 , 0.00842686, 0.00109119,\n",
       "        0.00560884, 0.00363647, 0.00080545, 0.00089349, 0.00749357,\n",
       "        0.00092018, 0.00204045, 0.00837209, 0.00154167, 0.00544101,\n",
       "        0.00147848, 0.0038373 , 0.00426762, 0.00651682, 0.0081088 ,\n",
       "        0.00194199, 0.00906396, 0.00193681, 0.00210547, 0.00273663,\n",
       "        0.00680472, 0.00098003, 0.00151706, 0.00538715, 0.00152192,\n",
       "        0.00364243, 0.00642125, 0.00112603, 0.00197532, 0.00224687,\n",
       "        0.00399323, 0.00102322, 0.00164756, 0.00476138, 0.00215845,\n",
       "        0.00091309, 0.0037442 , 0.00103094, 0.00782346, 0.00219116,\n",
       "        0.00146582, 0.00333082, 0.00090004, 0.00272847, 0.00382566,\n",
       "        0.00149922, 0.00243076, 0.00626842, 0.00084572, 0.00469272,\n",
       "        0.00330782, 0.00179305, 0.01039843, 0.00816727, 0.00890441,\n",
       "        0.00179165, 0.00113718, 0.00466834, 0.00593388, 0.00101783,\n",
       "        0.00843298, 0.00116814, 0.00252353, 0.0076126 , 0.00094662,\n",
       "        0.00726784, 0.00181101, 0.00653298, 0.00489618, 0.00078711,\n",
       "        0.00119966, 0.00781081, 0.0073789 , 0.00481145, 0.0048436 ,\n",
       "        0.0014354 , 0.00239274, 0.00188342, 0.00431367, 0.00424749,\n",
       "        0.00918687, 0.00218052, 0.00124908, 0.00201388, 0.00241757,\n",
       "        0.00103394, 0.00545297, 0.00139221, 0.0038129 , 0.00328971,\n",
       "        0.00765481, 0.00299371, 0.00188258, 0.00295897, 0.00193195,\n",
       "        0.00295299, 0.00186256, 0.00210934, 0.00026637, 0.00644779,\n",
       "        0.00155179, 0.00251425, 0.00241097, 0.00369684, 0.00356444,\n",
       "        0.00407555, 0.00373619, 0.0015406 , 0.00266926, 0.00643   ,\n",
       "        0.00606404, 0.00685484, 0.00134002, 0.00561735, 0.00137134,\n",
       "        0.0029443 , 0.00254506, 0.0019947 , 0.00218622, 0.0030541 ,\n",
       "        0.00264689, 0.00330282, 0.00582496, 0.00305366, 0.00255345,\n",
       "        0.00138434, 0.0016657 , 0.00924139, 0.00150032, 0.00310844,\n",
       "        0.0065387 , 0.00352807, 0.00924598, 0.00693631, 0.00505875,\n",
       "        0.00306977, 0.00519659, 0.00161793, 0.00370666, 0.00117143,\n",
       "        0.00219438, 0.00567642]),\n",
       " 'param_clf__estimator': masked_array(data=[LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__C': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__digits': masked_array(data=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__emoji': masked_array(data=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__lower': masked_array(data=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__metadata': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__negation_expand': masked_array(data=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__normalize': masked_array(data=[False, False, False, False, False, False, False, False,\n",
       "                    True, True, True, True, True, True, True, True, False,\n",
       "                    False, False, False, False, False, False, False, True,\n",
       "                    True, True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True, False, False,\n",
       "                    False, False, False, False, False, False, True, True,\n",
       "                    True, True, True, True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__punctuation': masked_array(data=[False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True,\n",
       "                    False, False, False, False, True, True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__stemming': masked_array(data=[False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True,\n",
       "                    False, False, True, True, False, False, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocess__stopwords': masked_array(data=[False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vectorizer__max_features': masked_array(data=[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vectorizer__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1),\n",
       "                    (1, 1)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vectorizer__stop_words': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, None, None, None],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': False,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': False,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': False,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 1,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': False,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': False,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': False,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': False,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': False,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None},\n",
       "  {'clf__estimator': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "             tol=0.0001, verbose=0, warm_start=False),\n",
       "   'clf__estimator__C': 1,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'preprocess__digits': True,\n",
       "   'preprocess__emoji': True,\n",
       "   'preprocess__lower': True,\n",
       "   'preprocess__metadata': 2,\n",
       "   'preprocess__negation_expand': True,\n",
       "   'preprocess__normalize': True,\n",
       "   'preprocess__punctuation': True,\n",
       "   'preprocess__stemming': True,\n",
       "   'preprocess__stopwords': True,\n",
       "   'vectorizer__max_features': 1000,\n",
       "   'vectorizer__ngram_range': (1, 1),\n",
       "   'vectorizer__stop_words': None}],\n",
       " 'split0_test_AUC': array([0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258, 0.89010258, 0.89010258, 0.89010258,\n",
       "        0.89010258, 0.89010258]),\n",
       " 'split1_test_AUC': array([0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464, 0.94626464, 0.94626464, 0.94626464,\n",
       "        0.94626464, 0.94626464]),\n",
       " 'split2_test_AUC': array([0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534, 0.90758534, 0.90758534, 0.90758534,\n",
       "        0.90758534, 0.90758534]),\n",
       " 'split3_test_AUC': array([0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997, 0.91156997, 0.91156997, 0.91156997,\n",
       "        0.91156997, 0.91156997]),\n",
       " 'split4_test_AUC': array([0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207, 0.92613207, 0.92613207, 0.92613207,\n",
       "        0.92613207, 0.92613207]),\n",
       " 'mean_test_AUC': array([0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092, 0.91633092, 0.91633092, 0.91633092,\n",
       "        0.91633092, 0.91633092]),\n",
       " 'std_test_AUC': array([0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355, 0.01886355, 0.01886355, 0.01886355,\n",
       "        0.01886355, 0.01886355]),\n",
       " 'rank_test_AUC': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_train_AUC': array([0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004, 0.98168004, 0.98168004, 0.98168004,\n",
       "        0.98168004, 0.98168004]),\n",
       " 'split1_train_AUC': array([0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813, 0.98077813, 0.98077813, 0.98077813,\n",
       "        0.98077813, 0.98077813]),\n",
       " 'split2_train_AUC': array([0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838, 0.98444838, 0.98444838, 0.98444838,\n",
       "        0.98444838, 0.98444838]),\n",
       " 'split3_train_AUC': array([0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009, 0.97975009, 0.97975009, 0.97975009,\n",
       "        0.97975009, 0.97975009]),\n",
       " 'split4_train_AUC': array([0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223, 0.97995223, 0.97995223, 0.97995223,\n",
       "        0.97995223, 0.97995223]),\n",
       " 'mean_train_AUC': array([0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177, 0.98132177, 0.98132177, 0.98132177,\n",
       "        0.98132177, 0.98132177]),\n",
       " 'std_train_AUC': array([0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056, 0.0017056,\n",
       "        0.0017056, 0.0017056]),\n",
       " 'split0_test_Accuracy': array([0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354, 0.87277354, 0.87277354, 0.87277354,\n",
       "        0.87277354, 0.87277354]),\n",
       " 'split1_test_Accuracy': array([0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524, 0.89058524, 0.89058524, 0.89058524,\n",
       "        0.89058524, 0.89058524]),\n",
       " 'split2_test_Accuracy': array([0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919, 0.84223919, 0.84223919, 0.84223919,\n",
       "        0.84223919, 0.84223919]),\n",
       " 'split3_test_Accuracy': array([0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995]),\n",
       " 'split4_test_Accuracy': array([0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995, 0.86513995, 0.86513995, 0.86513995,\n",
       "        0.86513995, 0.86513995]),\n",
       " 'mean_test_Accuracy': array([0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557, 0.86717557, 0.86717557, 0.86717557,\n",
       "        0.86717557, 0.86717557]),\n",
       " 'std_test_Accuracy': array([0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288, 0.01555288, 0.01555288, 0.01555288,\n",
       "        0.01555288, 0.01555288]),\n",
       " 'rank_test_Accuracy': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_train_Accuracy': array([0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092]),\n",
       " 'split1_train_Accuracy': array([0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478, 0.92684478, 0.92684478, 0.92684478,\n",
       "        0.92684478, 0.92684478]),\n",
       " 'split2_train_Accuracy': array([0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611, 0.93320611, 0.93320611, 0.93320611,\n",
       "        0.93320611, 0.93320611]),\n",
       " 'split3_train_Accuracy': array([0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092, 0.92748092, 0.92748092, 0.92748092,\n",
       "        0.92748092, 0.92748092]),\n",
       " 'split4_train_Accuracy': array([0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158, 0.93066158, 0.93066158, 0.93066158,\n",
       "        0.93066158, 0.93066158]),\n",
       " 'mean_train_Accuracy': array([0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486, 0.92913486, 0.92913486, 0.92913486,\n",
       "        0.92913486, 0.92913486]),\n",
       " 'std_train_Accuracy': array([0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399, 0.00243399, 0.00243399, 0.00243399,\n",
       "        0.00243399, 0.00243399]),\n",
       " 'split0_test_Brier': array([-0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902, -0.09177902, -0.09177902, -0.09177902,\n",
       "        -0.09177902, -0.09177902]),\n",
       " 'split1_test_Brier': array([-0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292, -0.076292, -0.076292, -0.076292, -0.076292,\n",
       "        -0.076292, -0.076292]),\n",
       " 'split2_test_Brier': array([-0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275, -0.10811275, -0.10811275, -0.10811275,\n",
       "        -0.10811275, -0.10811275]),\n",
       " 'split3_test_Brier': array([-0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313, -0.09614313, -0.09614313, -0.09614313,\n",
       "        -0.09614313, -0.09614313]),\n",
       " 'split4_test_Brier': array([-0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977, -0.09033977, -0.09033977, -0.09033977,\n",
       "        -0.09033977, -0.09033977]),\n",
       " 'mean_test_Brier': array([-0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334, -0.09253334, -0.09253334, -0.09253334,\n",
       "        -0.09253334, -0.09253334]),\n",
       " 'std_test_Brier': array([0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608, 0.01024608, 0.01024608, 0.01024608,\n",
       "        0.01024608, 0.01024608]),\n",
       " 'rank_test_Brier': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_train_Brier': array([-0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289, -0.05355289, -0.05355289, -0.05355289,\n",
       "        -0.05355289, -0.05355289]),\n",
       " 'split1_train_Brier': array([-0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263, -0.05428263, -0.05428263, -0.05428263,\n",
       "        -0.05428263, -0.05428263]),\n",
       " 'split2_train_Brier': array([-0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324, -0.04973324, -0.04973324, -0.04973324,\n",
       "        -0.04973324, -0.04973324]),\n",
       " 'split3_train_Brier': array([-0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295, -0.05339295, -0.05339295, -0.05339295,\n",
       "        -0.05339295, -0.05339295]),\n",
       " 'split4_train_Brier': array([-0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243, -0.05398243, -0.05398243, -0.05398243,\n",
       "        -0.05398243, -0.05398243]),\n",
       " 'mean_train_Brier': array([-0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883, -0.05298883, -0.05298883, -0.05298883,\n",
       "        -0.05298883, -0.05298883]),\n",
       " 'std_train_Brier': array([0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578, 0.0016578,\n",
       "        0.0016578, 0.0016578]),\n",
       " 'split0_test_f1-score': array([0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497, 0.9251497,\n",
       "        0.9251497, 0.9251497]),\n",
       " 'split1_test_f1-score': array([0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941, 0.93353941, 0.93353941, 0.93353941,\n",
       "        0.93353941, 0.93353941]),\n",
       " 'split2_test_f1-score': array([0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066, 0.89836066, 0.89836066, 0.89836066,\n",
       "        0.89836066, 0.89836066]),\n",
       " 'split3_test_f1-score': array([0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378, 0.91465378, 0.91465378, 0.91465378,\n",
       "        0.91465378, 0.91465378]),\n",
       " 'split4_test_f1-score': array([0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152,\n",
       "        0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152, 0.9152]),\n",
       " 'mean_test_f1-score': array([0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071, 0.91738071, 0.91738071, 0.91738071,\n",
       "        0.91738071, 0.91738071]),\n",
       " 'std_test_f1-score': array([0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335, 0.01179335, 0.01179335, 0.01179335,\n",
       "        0.01179335, 0.01179335]),\n",
       " 'rank_test_f1-score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_train_f1-score': array([0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933, 0.9533933,\n",
       "        0.9533933, 0.9533933]),\n",
       " 'split1_train_f1-score': array([0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033, 0.95361033, 0.95361033, 0.95361033,\n",
       "        0.95361033, 0.95361033]),\n",
       " 'split2_train_f1-score': array([0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988, 0.95857988, 0.95857988, 0.95857988,\n",
       "        0.95857988, 0.95857988]),\n",
       " 'split3_train_f1-score': array([0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167, 0.95458167, 0.95458167, 0.95458167,\n",
       "        0.95458167, 0.95458167]),\n",
       " 'split4_train_f1-score': array([0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703, 0.95648703, 0.95648703, 0.95648703,\n",
       "        0.95648703, 0.95648703]),\n",
       " 'mean_train_f1-score': array([0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044, 0.95533044, 0.95533044, 0.95533044,\n",
       "        0.95533044, 0.95533044]),\n",
       " 'std_train_f1-score': array([0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799, 0.00195799, 0.00195799, 0.00195799,\n",
       "        0.00195799, 0.00195799]),\n",
       " 'split0_test_precision': array([0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442, 0.91150442, 0.91150442, 0.91150442,\n",
       "        0.91150442, 0.91150442]),\n",
       " 'split1_test_precision': array([0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254, 0.90149254, 0.90149254, 0.90149254,\n",
       "        0.90149254, 0.90149254]),\n",
       " 'split2_test_precision': array([0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303, 0.83030303, 0.83030303, 0.83030303,\n",
       "        0.83030303, 0.83030303]),\n",
       " 'split3_test_precision': array([0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366, 0.86585366, 0.86585366, 0.86585366,\n",
       "        0.86585366, 0.86585366]),\n",
       " 'split4_test_precision': array([0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834, 0.86404834, 0.86404834, 0.86404834,\n",
       "        0.86404834, 0.86404834]),\n",
       " 'mean_test_precision': array([0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404, 0.8746404,\n",
       "        0.8746404, 0.8746404]),\n",
       " 'std_test_precision': array([0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393, 0.02910393, 0.02910393, 0.02910393,\n",
       "        0.02910393, 0.02910393]),\n",
       " 'rank_test_precision': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_train_precision': array([0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414, 0.92028414, 0.92028414, 0.92028414,\n",
       "        0.92028414, 0.92028414]),\n",
       " 'split1_train_precision': array([0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825, 0.92127825, 0.92127825, 0.92127825,\n",
       "        0.92127825, 0.92127825]),\n",
       " 'split2_train_precision': array([0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979, 0.92960979, 0.92960979, 0.92960979,\n",
       "        0.92960979, 0.92960979]),\n",
       " 'split3_train_precision': array([0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653, 0.92509653, 0.92509653, 0.92509653,\n",
       "        0.92509653, 0.92509653]),\n",
       " 'split4_train_precision': array([0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282, 0.92796282, 0.92796282, 0.92796282,\n",
       "        0.92796282, 0.92796282]),\n",
       " 'mean_train_precision': array([0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631, 0.92484631, 0.92484631, 0.92484631,\n",
       "        0.92484631, 0.92484631]),\n",
       " 'std_train_precision': array([0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347, 0.00363347, 0.00363347, 0.00363347,\n",
       "        0.00363347, 0.00363347]),\n",
       " 'split0_test_recall': array([0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973, 0.93920973, 0.93920973, 0.93920973,\n",
       "        0.93920973, 0.93920973]),\n",
       " 'split1_test_recall': array([0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872, 0.96794872, 0.96794872, 0.96794872,\n",
       "        0.96794872, 0.96794872]),\n",
       " 'split2_test_recall': array([0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143]),\n",
       " 'split3_test_recall': array([0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328, 0.96928328, 0.96928328, 0.96928328,\n",
       "        0.96928328, 0.96928328]),\n",
       " 'split4_test_recall': array([0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912, 0.97278912, 0.97278912, 0.97278912,\n",
       "        0.97278912, 0.97278912]),\n",
       " 'mean_test_recall': array([0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045, 0.96556045, 0.96556045, 0.96556045,\n",
       "        0.96556045, 0.96556045]),\n",
       " 'std_test_recall': array([0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818, 0.01367818, 0.01367818, 0.01367818,\n",
       "        0.01367818, 0.01367818]),\n",
       " 'rank_test_recall': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_train_recall': array([0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371, 0.98897371, 0.98897371, 0.98897371,\n",
       "        0.98897371, 0.98897371]),\n",
       " 'split1_train_recall': array([0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431, 0.98829431, 0.98829431, 0.98829431,\n",
       "        0.98829431, 0.98829431]),\n",
       " 'split2_train_recall': array([0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368, 0.98941368, 0.98941368, 0.98941368,\n",
       "        0.98941368, 0.98941368]),\n",
       " 'split3_train_recall': array([0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823, 0.98600823, 0.98600823, 0.98600823,\n",
       "        0.98600823, 0.98600823]),\n",
       " 'split4_train_recall': array([0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043, 0.98682043, 0.98682043, 0.98682043,\n",
       "        0.98682043, 0.98682043]),\n",
       " 'mean_train_recall': array([0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207, 0.98790207, 0.98790207, 0.98790207,\n",
       "        0.98790207, 0.98790207]),\n",
       " 'std_train_recall': array([0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181, 0.00129181, 0.00129181, 0.00129181,\n",
       "        0.00129181, 0.00129181])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocess', NLP_transformer(digits=False, emoji=False, lower=False, metadata=1,\n",
       "        negation_expand=False, negation_mark=None, normalize=False,\n",
       "        punctuation=False, stemming=False, stopwords=False)), ('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='stri...enalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
